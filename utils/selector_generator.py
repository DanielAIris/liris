#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
utils/selector_generator.py
GÃ©nÃ©rateur universel COMPLET avec support THINKING + DÃ‰TECTION + EXTRACTION
Version corrigÃ©e qui restaure le support thinking + amÃ©liorations Gemini rÃ©elles
"""

import re
from typing import Dict, List, Tuple, Optional


class UniversalSelectorGenerator:
    """
    GÃ©nÃ©rateur intelligent de sÃ©lecteurs pour THINKING + DÃ‰TECTION + EXTRACTION
    """
    
    def __init__(self):
        self.platform_patterns = {
            'claude': [
                'data-is-streaming',
                'claude-message',
                'anthropic',
                'claude.ai',
                'antml:thinking'  # ðŸ†• Pattern thinking
            ],
            'chatgpt': [
                'data-message-author-role="assistant"',
                'data-start',
                'data-end',
                'openai',
                'chatgpt',
                'data-testid="conversation-turn'
            ],
            'gemini': [
                'ms-text-chunk',           # âœ… Garde
                'ms-cmark-node',           # âœ… Garde  
                'ms-chat-turn',            # ðŸ†• AJOUTÃ‰ - conteneur principal
                'ms-thought-chunk',        # ðŸ†• AJOUTÃ‰ - thinking rÃ©el
                'ms-prompt-chunk',         # ðŸ†• AJOUTÃ‰ - conteneur prompt
                '_ngcontent-ng-c',         # âœ… Garde
                'aistudio.google.com',     # âœ… Garde
                'gemini',                  # âœ… Garde
                'model-run-time-pill'      # ðŸ†• AJOUTÃ‰ - indicateur temps
            ],
            'grok': [
                'response-content-markdown',
                'grok',
                'x.ai',
                'text-current'
            ],
            'deepseek': [
                'ds-markdown',
                'deepseek',
                'ds-markdown--block'
            ]
        }
        
        # ðŸ†• RESTAURÃ‰ : Patterns de dÃ©tection thinking
        self.thinking_patterns = {
            'claude': ['antml:thinking', 'thinking-block', 'reasoning-phase'],
            'chatgpt': ['thinking-indicator', 'o1-thinking'],  # Pour o1
            'gemini': [
                'ms-thought-chunk',              # ðŸ†• RÃ‰EL - trouvÃ© dans HTML
                'thinking-progress-icon',        # ðŸ†• RÃ‰EL - icÃ´ne thinking
                'thought-panel',                 # ðŸ†• RÃ‰EL - panel thinking
                'mat-expansion-panel',           # ðŸ†• RÃ‰EL - conteneur expandable
                'thinking-process',              # âœ… Garde (gÃ©nÃ©rique)
                'reasoning-step'                 # âœ… Garde (gÃ©nÃ©rique)
            ],
            'grok': ['thought-process', 'reasoning-mode'],
            'deepseek': ['thinking-stage', 'analysis-phase']
        }
    
    def analyze_html_and_generate_selectors(self, html_content: str) -> Dict:
        """
        ðŸ†• RESTAURÃ‰ : Analyse avec support thinking
        
        Returns:
            {
                'platform': 'claude|chatgpt|gemini|grok|deepseek',
                'has_thinking_phase': bool,  # ðŸ†• RESTAURÃ‰
                'thinking': {  # ðŸ†• RESTAURÃ‰
                    'selector': 'sÃ©lecteur pour phase thinking',
                    'completion_indicator': 'comment dÃ©tecter fin thinking'
                } | None,
                'detection': {
                    'method': 'thinking_then_streaming|attribute_monitoring|etc',
                    'primary_selector': 'sÃ©lecteur pour dÃ©tecter fin response',
                    'fallback_selectors': ['fallbacks'],
                    'script_type': 'specialized|generic'
                },
                'extraction': {
                    'primary_selector': 'sÃ©lecteur pour extraire texte final',
                    'fallback_selectors': ['fallbacks'],
                    'text_cleaning': 'mÃ©thode de nettoyage'
                }
            }
        """
        
        # 1. DÃ©tection automatique de la plateforme
        platform = self._detect_platform(html_content)
        
        # 2. ðŸ†• RESTAURÃ‰ : DÃ©tection phase thinking
        has_thinking = self._detect_thinking_phase(platform, html_content)
        
        # 3. GÃ©nÃ©ration des sÃ©lecteurs selon la plateforme et thinking
        if platform == 'claude':
            return self._generate_claude_selectors(html_content, has_thinking)
        elif platform == 'chatgpt':
            return self._generate_chatgpt_selectors(html_content, has_thinking)
        elif platform == 'gemini':
            return self._generate_gemini_selectors(html_content, has_thinking)
        elif platform == 'grok':
            return self._generate_grok_selectors(html_content, has_thinking)
        elif platform == 'deepseek':
            return self._generate_deepseek_selectors(html_content, has_thinking)
        else:
            return self._generate_generic_selectors(html_content, has_thinking)
    
    def _detect_platform(self, html_content: str) -> str:
        """DÃ©tecte automatiquement la plateforme basÃ©e sur les patterns HTML"""
        html_lower = html_content.lower()
        
        scores = {'claude': 0, 'chatgpt': 0, 'gemini': 0, 'grok': 0, 'deepseek': 0}
        
        for platform, patterns in self.platform_patterns.items():
            for pattern in patterns:
                if pattern.lower() in html_lower:
                    scores[platform] += 1
        
        detected = max(scores, key=scores.get)
        print(f"ðŸ” Plateforme dÃ©tectÃ©e: {detected} (scores: {scores})")
        return detected
    
    def _detect_thinking_phase(self, platform: str, html_content: str) -> bool:
        """ðŸ†• RESTAURÃ‰ : DÃ©tecte si l'IA utilise une phase thinking"""
        if platform not in self.thinking_patterns:
            return False
            
        html_lower = html_content.lower()
        patterns = self.thinking_patterns[platform]
        
        for pattern in patterns:
            if pattern.lower() in html_lower:
                print(f"ðŸ§  Phase thinking dÃ©tectÃ©e: {pattern} pour {platform}")
                return True
                
        return False
    
    def _generate_claude_selectors(self, html_content: str, has_thinking: bool) -> Dict:
        """ðŸ†• RESTAURÃ‰ : GÃ©nÃ©rateur Claude amÃ©liorÃ© avec support thinking"""
        
        base_config = {
            'platform': 'claude',
            'has_thinking_phase': has_thinking
        }
        
        if has_thinking:
            # ðŸ§  CAS THINKING â†’ RESPONSE
            base_config.update({
                'thinking': {
                    'selector': 'antml\\:thinking',
                    'completion_indicator': 'antml\\:thinking[complete="true"]',
                    'description': 'Phase de rÃ©flexion Claude'
                },
                'detection': {
                    'method': 'thinking_then_streaming',
                    'primary_selector': 'antml\\:thinking[complete="true"] ~ [data-is-streaming="false"]',
                    'fallback_selectors': [
                        '[data-is-streaming="false"]:has(+ antml\\:thinking[complete])',
                        'antml\\:thinking[complete] + .font-claude-message'
                    ],
                    'script_type': 'thinking_specialized',
                    'description': 'Attendre thinking complete PUIS streaming false'
                }
            })
        else:
            # âœ… CAS NORMAL (pas de rÃ©gression)
            base_config.update({
                'thinking': None,
                'detection': {
                    'method': 'attribute_monitoring',
                    'primary_selector': '[data-is-streaming="false"]',
                    'fallback_selectors': [
                        '[data-is-streaming]',
                        '.font-claude-message',
                        'div[data-test-render-count]'
                    ],
                    'script_type': 'specialized',
                    'description': 'Surveille l\'attribut data-is-streaming'
                }
            })
        
        # Extraction reste identique
        base_config['extraction'] = {
            'primary_selector': '.font-claude-message:last-child',
            'fallback_selectors': [
                '[data-is-streaming="false"] .font-claude-message',
                'div[data-test-render-count] div:last-child',
                '.group.relative:last-child'
            ],
            'text_cleaning': 'remove_ui_elements',
            'description': 'Extrait depuis le conteneur de message Claude'
        }
        
        return base_config
    
    def _generate_chatgpt_selectors(self, html_content: str, has_thinking: bool) -> Dict:
        """ðŸ†• RESTAURÃ‰ : GÃ©nÃ©rateur ChatGPT avec support o1 thinking"""
        
        base_config = {
            'platform': 'chatgpt',
            'has_thinking_phase': has_thinking
        }
        
        if has_thinking:
            # ðŸ§  CAS O1 THINKING â†’ RESPONSE
            base_config.update({
                'thinking': {
                    'selector': '.thinking-indicator, .o1-thinking',
                    'completion_indicator': '.thinking-indicator[complete], .o1-thinking[data-complete="true"]',
                    'description': 'Phase thinking o1'
                },
                'detection': {
                    'method': 'thinking_then_data_stability',
                    'primary_selector': '.thinking-indicator[complete] ~ [data-start][data-end]',
                    'fallback_selectors': [
                        '[data-start][data-end]:not(:has(.thinking-indicator:not([complete])))',
                        '.o1-thinking[data-complete] + [data-message-author-role="assistant"]'
                    ],
                    'script_type': 'thinking_specialized',
                    'description': 'Attendre thinking complete PUIS data stability'
                }
            })
        else:
            # âœ… CAS NORMAL ChatGPT
            base_config.update({
                'thinking': None,
                'detection': {
                    'method': 'chatgpt_data_stability',
                    'primary_selector': '[data-start][data-end]',
                    'fallback_selectors': [
                        '[data-message-author-role="assistant"]:last-child [data-start]',
                        'div[data-message-id]:last-child [data-start]'
                    ],
                    'script_type': 'specialized',
                    'description': 'Surveille stabilitÃ© data-start/data-end'
                }
            })
        
        base_config['extraction'] = {
            'primary_selector': 'article[data-testid*="conversation-turn"]:last-child',
            'fallback_selectors': [
                '[data-message-author-role="assistant"]:last-child .markdown',
                'div[data-message-id]:last-child .prose'
            ],
            'text_cleaning': 'preserve_markdown_structure',
            'description': 'Extrait depuis conteneur markdown ChatGPT'
        }
        
        return base_config
    
    def _generate_gemini_selectors(self, html_content: str, has_thinking: bool) -> Dict:
        """ðŸ”§ GÃ‰NÃ‰RATEUR GEMINI AMÃ‰LIORÃ‰ basÃ© sur HTML rÃ©el"""
        
        base_config = {
            'platform': 'gemini',
            'has_thinking_phase': has_thinking
        }
        
        if has_thinking:
            # ðŸ§  CAS THINKING GEMINI RÃ‰EL
            base_config.update({
                'thinking': {
                    'selector': 'ms-thought-chunk',                           # ðŸ†• RÃ‰EL
                    'completion_indicator': 'ms-thought-chunk:not(:has(.thinking-progress-icon.in-progress))',  # ðŸ†• RÃ‰EL
                    'alternative_completion': 'mat-expansion-panel.thought-panel:not(:has(.in-progress))',       # ðŸ†• RÃ‰EL
                    'description': 'Phase thinking Gemini rÃ©elle'
                },
                'detection': {
                    'method': 'thinking_then_element_absence',
                    'primary_selector': 'ms-thought-chunk:not(:has(.thinking-progress-icon.in-progress)) ~ ms-chat-turn:not(:has(loading-indicator))',
                    'fallback_selectors': [
                        'ms-chat-turn:has(ms-thought-chunk):not(:has(loading-indicator))',   # ðŸ†• Chat-turn avec thinking complete
                        'ms-chat-turn:has(.model-run-time-pill)',                           # ðŸ†• PrÃ©sence indicateur temps = fini
                        'ms-prompt-chunk:not(:has(.thinking-progress-icon.in-progress))',   # ðŸ†• Prompt chunk sans thinking actif
                        'ms-text-chunk:last-child:not(:has(.in-progress))'                  # ðŸ†• Dernier text-chunk stable
                    ],
                    'script_type': 'thinking_specialized',
                    'description': 'Attendre thinking complete PUIS absence loading'
                }
            })
        else:
            # âœ… CAS NORMAL GEMINI (amÃ©liorÃ©)
            base_config.update({
                'thinking': None,
                'detection': {
                    'method': 'gemini_completion_detection',
                    'primary_selector': 'ms-chat-turn:not(:has(loading-indicator)):has(.model-run-time-pill)',  # ðŸ†• AMÃ‰LIORÃ‰
                    'fallback_selectors': [
                        'ms-chat-turn:not(:has(loading-indicator))',                     # âœ… Original
                        'ms-text-chunk:not(:has(.in-progress))',                        # âœ… Original
                        'ms-prompt-chunk:has(.model-run-time-pill)',                    # ðŸ†• Avec temps = fini
                        '.model-response:last-child',                                   # âœ… Original
                        'ms-chat-turn:has(.turn-footer)'                               # ðŸ†• Footer prÃ©sent = fini
                    ],
                    'script_type': 'specialized',
                    'description': 'Surveille absence loading + prÃ©sence temps exÃ©cution'
                }
            })
        
        # ðŸ”§ EXTRACTION AMÃ‰LIORÃ‰E
        base_config['extraction'] = {
            'primary_selector': 'ms-text-chunk:last-child',                          # âœ… Garde
            'fallback_selectors': [
                'ms-text-chunk ms-cmark-node span.ng-star-inserted',                # âœ… Garde
                'ms-cmark-node span',                                               # âœ… Garde
                'ms-prompt-chunk ms-text-chunk:last-child',                        # ðŸ†• AJOUTÃ‰
                'ms-chat-turn .model-prompt-container ms-text-chunk:last-child'    # ðŸ†• AJOUTÃ‰
            ],
            'text_cleaning': 'gemini_enhanced_extraction',                          # ðŸ†• AMÃ‰LIORÃ‰
            'description': 'Extrait depuis spans imbriquÃ©s Gemini avec fallbacks renforcÃ©s'
        }
        
        return base_config
    
    def _generate_grok_selectors(self, html_content: str, has_thinking: bool) -> Dict:
        """GÃ©nÃ©rateur Grok (thinking potentiel futur)"""
        base_config = {
            'platform': 'grok',
            'has_thinking_phase': has_thinking,
            'thinking': None if not has_thinking else {
                'selector': '.thought-process, .reasoning-mode',
                'completion_indicator': '.thought-process[complete]',
                'description': 'Phase thinking Grok (futur)'
            }
        }
        
        method = 'thinking_then_class_absence' if has_thinking else 'class_absence'
        selector = '.thought-process[complete] ~ .response-content-markdown' if has_thinking else '.response-content-markdown:not(:has(.generating))'
        
        base_config['detection'] = {
            'method': method,
            'primary_selector': selector,
            'fallback_selectors': [
                '.response-content-markdown',
                'div[class*="response"]:not(:has(.loading))'
            ],
            'script_type': 'thinking_specialized' if has_thinking else 'specialized',
            'description': 'Surveille thinking puis absence generating' if has_thinking else 'Surveille absence generating'
        }
        
        base_config['extraction'] = {
            'primary_selector': '.response-content-markdown',
            'fallback_selectors': [
                '.response-content-markdown p:last-child'
            ],
            'text_cleaning': 'grok_text_extraction',
            'description': 'Extrait depuis conteneur markdown Grok'
        }
        
        return base_config
    
    def _generate_deepseek_selectors(self, html_content: str, has_thinking: bool) -> Dict:
        """GÃ©nÃ©rateur DeepSeek (thinking potentiel futur)"""
        base_config = {
            'platform': 'deepseek',
            'has_thinking_phase': has_thinking,
            'thinking': None if not has_thinking else {
                'selector': '.thinking-stage, .analysis-phase',
                'completion_indicator': '.thinking-stage[complete]',
                'description': 'Phase thinking DeepSeek (futur)'
            }
        }
        
        method = 'thinking_then_element_stability' if has_thinking else 'element_stability'
        
        base_config['detection'] = {
            'method': method,
            'primary_selector': '.ds-markdown.ds-markdown--block',
            'fallback_selectors': [
                '.ds-markdown:last-child',
                'div[class*="ds-"]:last-child'
            ],
            'script_type': 'thinking_specialized' if has_thinking else 'specialized',
            'description': 'Surveille thinking puis stabilitÃ©' if has_thinking else 'Surveille stabilitÃ©'
        }
        
        base_config['extraction'] = {
            'primary_selector': '.ds-markdown.ds-markdown--block',
            'fallback_selectors': [
                '.ds-markdown:last-child'
            ],
            'text_cleaning': 'deepseek_text_extraction',
            'description': 'Extrait depuis conteneur markdown DeepSeek'
        }
        
        return base_config
    
    def _generate_generic_selectors(self, html_content: str, has_thinking: bool) -> Dict:
        """GÃ©nÃ©rateur gÃ©nÃ©rique"""
        classes = re.findall(r'class="([^"]*)"', html_content)
        primary_selector = 'div'
        if classes:
            for class_list in classes:
                for class_name in class_list.split():
                    if class_name and len(class_name) > 3:
                        primary_selector = f'.{class_name}'
                        break
                if primary_selector != 'div':
                    break
        
        return {
            'platform': 'generic',
            'has_thinking_phase': has_thinking,
            'thinking': None,
            'detection': {
                'method': 'element_stability',
                'primary_selector': primary_selector,
                'fallback_selectors': [
                    'div:last-child',
                    'p:last-child'
                ],
                'script_type': 'generic',
                'description': 'DÃ©tection gÃ©nÃ©rique stabilitÃ©'
            },
            'extraction': {
                'primary_selector': primary_selector,
                'fallback_selectors': [
                    'div:last-child',
                    'p:last-child'
                ],
                'text_cleaning': 'basic_text_extraction',
                'description': 'Extraction gÃ©nÃ©rique'
            }
        }
    
    def generate_detection_script(self, detection_config: Dict) -> str:
        """ðŸ†• RESTAURÃ‰ : GÃ©nÃ¨re script avec support thinking â†’ response"""
        
        has_thinking = detection_config.get('has_thinking_phase', False)
        platform = detection_config.get('platform', 'generic')
        method = detection_config['detection']['method']
        
        if has_thinking:
            # ðŸ§  SCRIPTS THINKING â†’ RESPONSE
            if platform == 'claude' and 'thinking_then' in method:
                return self._get_claude_thinking_script()
            elif platform == 'chatgpt' and 'thinking_then' in method:
                return self._get_chatgpt_thinking_script()
            elif platform == 'gemini' and 'thinking_then' in method:
                return self._get_gemini_thinking_script()
            else:
                return self._get_generic_thinking_script(detection_config)
        else:
            # âœ… SCRIPTS NORMAUX (pas de rÃ©gression)
            if platform == 'claude':
                return self._get_claude_detection_script()
            elif platform == 'chatgpt':
                return self._get_chatgpt_detection_script()
            elif platform == 'gemini':
                return self._get_gemini_detection_script()
            elif platform == 'grok':
                return self._get_grok_detection_script()
            elif platform == 'deepseek':
                return self._get_deepseek_detection_script()
            else:
                return self._get_generic_detection_script(detection_config['detection']['primary_selector'])
    
    # ðŸ†• RESTAURÃ‰ : Scripts thinking
    def _get_claude_thinking_script(self) -> str:
        """ðŸ§  Script Claude avec thinking â†’ streaming"""
        return '''
        (function() {
            let phase = 'waiting_thinking';
            let checkCount = 0;
            let maxChecks = 120;  // Plus long pour thinking
            
            function checkClaudeThinkingCompletion() {
                try {
                    checkCount++;
                    
                    if (checkCount > maxChecks) {
                        console.log("LIRIS_GENERATION_COMPLETE:timeout");
                        return;
                    }
                    
                    if (phase === 'waiting_thinking') {
                        // Phase 1: Attendre que thinking soit complete
                        let thinkingComplete = document.querySelector('antml\\\\:thinking[complete="true"]');
                        
                        if (thinkingComplete) {
                            console.log("Claude thinking phase complete, checking streaming...");
                            phase = 'waiting_streaming';
                        }
                    }
                    
                    if (phase === 'waiting_streaming') {
                        // Phase 2: Attendre que streaming soit false
                        let streamingElements = document.querySelectorAll('[data-is-streaming="true"]');
                        let completedElements = document.querySelectorAll('[data-is-streaming="false"]');
                        
                        if (streamingElements.length === 0 && completedElements.length > 0) {
                            console.log("LIRIS_GENERATION_COMPLETE:true");
                            return;
                        }
                    }
                    
                    setTimeout(checkClaudeThinkingCompletion, 400);
                } catch(e) {
                    console.log("LIRIS_GENERATION_COMPLETE:false");
                }
            }

            checkClaudeThinkingCompletion();
            return "Claude thinking detection started";
        })();
        '''
    
    def _get_chatgpt_thinking_script(self) -> str:
        """ðŸ§  Script ChatGPT o1 avec thinking â†’ response"""
        return '''
        (function() {
            let phase = 'waiting_thinking';
            let checkCount = 0;
            let maxChecks = 120;
            let lastDataState = '';
            let stableCount = 0;
            
            function checkChatGPTThinkingCompletion() {
                try {
                    checkCount++;
                    
                    if (checkCount > maxChecks) {
                        console.log("LIRIS_GENERATION_COMPLETE:timeout");
                        return;
                    }
                    
                    if (phase === 'waiting_thinking') {
                        // Phase 1: Attendre thinking complete
                        let thinkingComplete = document.querySelector('.thinking-indicator[complete], .o1-thinking[data-complete="true"]');
                        
                        if (thinkingComplete) {
                            console.log("ChatGPT thinking phase complete, checking response...");
                            phase = 'waiting_response';
                        }
                    }
                    
                    if (phase === 'waiting_response') {
                        // Phase 2: Attendre stabilitÃ© data-start/data-end
                        let elements = document.querySelectorAll('[data-start][data-end]');
                        let currentState = '';
                        elements.forEach(el => {
                            let start = el.getAttribute('data-start') || '';
                            let end = el.getAttribute('data-end') || '';
                            currentState += start + ':' + end + ';';
                        });
                        
                        if (currentState === lastDataState && currentState.length > 0) {
                            stableCount++;
                            if (stableCount >= 3) {
                                console.log("LIRIS_GENERATION_COMPLETE:true");
                                return;
                            }
                        } else {
                            lastDataState = currentState;
                            stableCount = 0;
                        }
                    }
                    
                    setTimeout(checkChatGPTThinkingCompletion, 400);
                } catch(e) {
                    console.log("LIRIS_GENERATION_COMPLETE:false");
                }
            }

            checkChatGPTThinkingCompletion();
            return "ChatGPT thinking detection started";
        })();
        '''
    
    def _get_gemini_thinking_script(self) -> str:
        """ðŸ†• SCRIPT THINKING GEMINI basÃ© sur HTML rÃ©el"""
        return '''
        (function() {
            let phase = 'waiting_thinking';
            let checkCount = 0;
            let maxChecks = 120;  // Thinking peut Ãªtre long
            let lastContentLength = 0;
            let stableCount = 0;
            
            function checkGeminiThinkingCompletion() {
                try {
                    checkCount++;
                    
                    if (checkCount > maxChecks) {
                        console.log("LIRIS_GENERATION_COMPLETE:timeout");
                        return;
                    }
                    
                    if (phase === 'waiting_thinking') {
                        // Phase 1: Attendre que thinking soit complete
                        let thinkingChunks = document.querySelectorAll('ms-thought-chunk');
                        let thinkingInProgress = document.querySelectorAll('ms-thought-chunk .thinking-progress-icon.in-progress');
                        
                        // Thinking complete si chunks prÃ©sents mais plus d'indicateur "in-progress"
                        if (thinkingChunks.length > 0 && thinkingInProgress.length === 0) {
                            console.log("Gemini thinking phase complete, checking response...");
                            phase = 'waiting_response';
                        }
                    }
                    
                    if (phase === 'waiting_response') {
                        // Phase 2: Attendre que la rÃ©ponse soit stable
                        
                        // VÃ©rifier temps d'exÃ©cution (plus fiable)
                        let timePills = document.querySelectorAll('.model-run-time-pill');
                        if (timePills.length > 0) {
                            let latestPill = timePills[timePills.length - 1];
                            let timeText = latestPill.textContent.trim();
                            if (timeText && timeText.includes('s')) {
                                console.log("LIRIS_GENERATION_COMPLETE:true (thinking + time)");
                                return;
                            }
                        }
                        
                        // VÃ©rifier stabilitÃ© contenu
                        let textChunks = document.querySelectorAll('ms-text-chunk');
                        let currentLength = 0;
                        textChunks.forEach(chunk => {
                            currentLength += (chunk.textContent || '').length;
                        });
                        
                        let loadingIndicators = document.querySelectorAll('loading-indicator, .in-progress');
                        
                        if (loadingIndicators.length === 0 && textChunks.length > 0) {
                            if (currentLength === lastContentLength && currentLength > 100) {
                                stableCount++;
                                if (stableCount >= 3) {
                                    console.log("LIRIS_GENERATION_COMPLETE:true (thinking + stable)");
                                    return;
                                }
                            } else {
                                lastContentLength = currentLength;
                                stableCount = 0;
                            }
                        }
                    }
                    
                    setTimeout(checkGeminiThinkingCompletion, 600);
                } catch(e) {
                    console.log("LIRIS_GENERATION_COMPLETE:false");
                }
            }

            checkGeminiThinkingCompletion();
            return "Gemini thinking detection started";
        })();
        '''
    
    def _get_generic_thinking_script(self, config: Dict) -> str:
        """ðŸ§  Script gÃ©nÃ©rique thinking â†’ response"""
        thinking_selector = config.get('thinking', {}).get('selector', '.thinking')
        response_selector = config['detection']['primary_selector']
        
        return f'''
        (function() {{
            let phase = 'waiting_thinking';
            let checkCount = 0;
            let maxChecks = 100;
            let lastText = '';
            let stableCount = 0;
            
            function checkGenericThinkingCompletion() {{
                try {{
                    checkCount++;
                    
                    if (checkCount > maxChecks) {{
                        console.log("LIRIS_GENERATION_COMPLETE:timeout");
                        return;
                    }}
                    
                    if (phase === 'waiting_thinking') {{
                        // Phase 1: Attendre thinking complete
                        let thinking = document.querySelector("{thinking_selector}");
                        
                        if (!thinking || thinking.getAttribute('complete') === 'true') {{
                            console.log("Generic thinking phase complete");
                            phase = 'waiting_response';
                        }}
                    }}
                    
                    if (phase === 'waiting_response') {{
                        // Phase 2: Attendre stabilitÃ© response
                        let element = document.querySelector("{response_selector}");
                        let currentText = element ? (element.textContent || '').trim() : '';
                        
                        if (currentText === lastText && currentText.length > 30) {{
                            stableCount++;
                            if (stableCount >= 3) {{
                                console.log("LIRIS_GENERATION_COMPLETE:true");
                                return;
                            }}
                        }} else {{
                            lastText = currentText;
                            stableCount = 0;
                        }}
                    }}
                    
                    setTimeout(checkGenericThinkingCompletion, 500);
                }} catch(e) {{
                    console.log("LIRIS_GENERATION_COMPLETE:false");
                }}
            }}

            checkGenericThinkingCompletion();
            return "Generic thinking detection started";
        }})();
        '''
    
    # âœ… Scripts normaux inchangÃ©s (pas de rÃ©gression)
    def _get_claude_detection_script(self) -> str:
        return '''
        (function() {
            let checkCount = 0;
            let maxChecks = 60;
            
            function checkClaudeCompletion() {
                try {
                    checkCount++;
                    
                    if (checkCount > maxChecks) {
                        console.log("LIRIS_GENERATION_COMPLETE:timeout");
                        return;
                    }
                    
                    let streamingElements = document.querySelectorAll('[data-is-streaming="true"]');
                    let completedElements = document.querySelectorAll('[data-is-streaming="false"]');
                    
                    if (streamingElements.length === 0 && completedElements.length > 0) {
                        console.log("LIRIS_GENERATION_COMPLETE:true");
                        return;
                    }
                    
                    setTimeout(checkClaudeCompletion, 300);
                } catch(e) {
                    console.log("LIRIS_GENERATION_COMPLETE:false");
                }
            }

            checkClaudeCompletion();
            return "Claude detection started";
        })();
        '''
    
    def _get_chatgpt_detection_script(self) -> str:
        return '''
        (function() {
            let lastDataState = '';
            let stableCount = 0;
            let checkCount = 0;
            let maxChecks = 60;
            
            function checkChatGPTCompletion() {
                try {
                    checkCount++;
                    
                    if (checkCount > maxChecks) {
                        console.log("LIRIS_GENERATION_COMPLETE:timeout");
                        return;
                    }
                    
                    let elements = document.querySelectorAll('[data-start][data-end]');
                    let currentState = '';
                    elements.forEach(el => {
                        let start = el.getAttribute('data-start') || '';
                        let end = el.getAttribute('data-end') || '';
                        currentState += start + ':' + end + ';';
                    });
                    
                    if (currentState === lastDataState && currentState.length > 0) {
                        stableCount++;
                        if (stableCount >= 3) {
                            console.log("LIRIS_GENERATION_COMPLETE:true");
                            return;
                        }
                    } else {
                        lastDataState = currentState;
                        stableCount = 0;
                    }
                    
                    setTimeout(checkChatGPTCompletion, 300);
                } catch(e) {
                    console.log("LIRIS_GENERATION_COMPLETE:false");
                }
            }

            checkChatGPTCompletion();
            return "ChatGPT detection started";
        })();
        '''
    
    def _get_gemini_detection_script(self) -> str:
        """ðŸ”§ SCRIPT DÃ‰TECTION GEMINI AMÃ‰LIORÃ‰"""
        return '''
        (function() {
            let checkCount = 0;
            let maxChecks = 80;  // Plus long pour Gemini
            let lastContentLength = 0;
            let stableCount = 0;
            
            function checkGeminiCompletion() {
                try {
                    checkCount++;
                    
                    if (checkCount > maxChecks) {
                        console.log("LIRIS_GENERATION_COMPLETE:timeout");
                        return;
                    }
                    
                    // ðŸ†• MÃ‰THODE 1: VÃ©rifier prÃ©sence temps exÃ©cution (le plus fiable)
                    let timePills = document.querySelectorAll('.model-run-time-pill');
                    if (timePills.length > 0) {
                        // S'il y a un temps affichÃ©, c'est probablement fini
                        let latestPill = timePills[timePills.length - 1];
                        let timeText = latestPill.textContent.trim();
                        if (timeText && timeText.includes('s')) {
                            console.log("LIRIS_GENERATION_COMPLETE:true (time indicator)");
                            return;
                        }
                    }
                    
                    // ðŸ†• MÃ‰THODE 2: VÃ©rifier absence d'indicateurs de chargement
                    let loadingIndicators = document.querySelectorAll(
                        'loading-indicator, .thinking-progress-icon.in-progress, .generating, .in-progress'
                    );
                    
                    // ðŸ†• MÃ‰THODE 3: VÃ©rifier stabilitÃ© du contenu
                    let textChunks = document.querySelectorAll('ms-text-chunk');
                    let currentLength = 0;
                    textChunks.forEach(chunk => {
                        currentLength += (chunk.textContent || '').length;
                    });
                    
                    // âœ… CONDITION COMBINÃ‰E
                    let hasContent = textChunks.length > 0;
                    let noLoading = loadingIndicators.length === 0;
                    let contentStable = currentLength === lastContentLength && currentLength > 50;
                    
                    if (hasContent && noLoading) {
                        if (contentStable) {
                            stableCount++;
                            if (stableCount >= 3) {
                                console.log("LIRIS_GENERATION_COMPLETE:true (stable content)");
                                return;
                            }
                        } else {
                            lastContentLength = currentLength;
                            stableCount = 0;
                        }
                    }
                    
                    setTimeout(checkGeminiCompletion, 500);  // Plus lent pour Gemini
                } catch(e) {
                    console.log("LIRIS_GENERATION_COMPLETE:false");
                }
            }

            checkGeminiCompletion();
            return "Enhanced Gemini detection started";
        })();
        '''
    
    def _get_grok_detection_script(self) -> str:
        return '''
        (function() {
            let checkCount = 0;
            let maxChecks = 60;
            
            function checkGrokCompletion() {
                try {
                    checkCount++;
                    
                    if (checkCount > maxChecks) {
                        console.log("LIRIS_GENERATION_COMPLETE:timeout");
                        return;
                    }
                    
                    let generatingElements = document.querySelectorAll('.generating, .loading');
                    let contentElements = document.querySelectorAll('.response-content-markdown');
                    
                    if (generatingElements.length === 0 && contentElements.length > 0) {
                        console.log("LIRIS_GENERATION_COMPLETE:true");
                        return;
                    }
                    
                    setTimeout(checkGrokCompletion, 400);
                } catch(e) {
                    console.log("LIRIS_GENERATION_COMPLETE:false");
                }
            }

            checkGrokCompletion();
            return "Grok detection started";
        })();
        '''
    
    def _get_deepseek_detection_script(self) -> str:
        return '''
        (function() {
            let lastLength = 0;
            let stableCount = 0;
            let checkCount = 0;
            let maxChecks = 60;
            
            function checkDeepSeekCompletion() {
                try {
                    checkCount++;
                    
                    if (checkCount > maxChecks) {
                        console.log("LIRIS_GENERATION_COMPLETE:timeout");
                        return;
                    }
                    
                    let elements = document.querySelectorAll('.ds-markdown.ds-markdown--block');
                    let totalLength = 0;
                    
                    for (let el of elements) {
                        totalLength += (el.textContent || '').length;
                    }
                    
                    if (totalLength === lastLength && totalLength > 50) {
                        stableCount++;
                        if (stableCount >= 3) {
                            console.log("LIRIS_GENERATION_COMPLETE:true");
                            return;
                        }
                    } else {
                        lastLength = totalLength;
                        stableCount = 0;
                    }
                    
                    setTimeout(checkDeepSeekCompletion, 400);
                } catch(e) {
                    console.log("LIRIS_GENERATION_COMPLETE:false");
                }
            }

            checkDeepSeekCompletion();
            return "DeepSeek detection started";
        })();
        '''
    
    def _get_generic_detection_script(self, selector: str) -> str:
        return f'''
        (function() {{
            let lastText = '';
            let stableCount = 0;
            let checkCount = 0;
            let maxChecks = 50;
            
            function checkGenericCompletion() {{
                try {{
                    checkCount++;
                    
                    if (checkCount > maxChecks) {{
                        console.log("LIRIS_GENERATION_COMPLETE:timeout");
                        return;
                    }}
                    
                    let element = document.querySelector("{selector}");
                    let currentText = element ? (element.textContent || '').trim() : '';
                    
                    if (currentText === lastText && currentText.length > 30) {{
                        stableCount++;
                        if (stableCount >= 3) {{
                            console.log("LIRIS_GENERATION_COMPLETE:true");
                            return;
                        }}
                    }} else {{
                        lastText = currentText;
                        stableCount = 0;
                    }}
                    
                    setTimeout(checkGenericCompletion, 500);
                }} catch(e) {{
                    console.log("LIRIS_GENERATION_COMPLETE:false");
                }}
            }}

            checkGenericCompletion();
            return "Generic detection started";
        }})();
        '''


# âœ… Test avec thinking et sans thinking
def test_thinking_support():
    generator = UniversalSelectorGenerator()
    
    print("=== TEST CLAUDE SANS THINKING ===")
    claude_normal = '''<div data-is-streaming="false" class="font-claude-message">RÃ©ponse simple</div>'''
    config_normal = generator.analyze_html_and_generate_selectors(claude_normal)
    print(f"Has thinking: {config_normal['has_thinking_phase']}")
    print(f"Detection method: {config_normal['detection']['method']}")
    print(f"Primary selector: {config_normal['detection']['primary_selector']}")
    
    print("\n=== TEST CLAUDE AVEC THINKING ===")
    claude_thinking = '''<thinking complete="true">Analysons cela...</thinking><div data-is-streaming="false" class="font-claude-message">Voici ma rÃ©ponse</div>'''
    config_thinking = generator.analyze_html_and_generate_selectors(claude_thinking)
    print(f"Has thinking: {config_thinking['has_thinking_phase']}")
    print(f"Thinking selector: {config_thinking['thinking']['selector']}")
    print(f"Detection method: {config_thinking['detection']['method']}")
    print(f"Primary selector: {config_thinking['detection']['primary_selector']}")

    print("\n=== TEST GEMINI THINKING RÃ‰EL ===")
    gemini_thinking_html = '''
    <ms-chat-turn _ngcontent-ng-c4177798910="" _nghost-ng-c3182747720="" id="turn-B0E69BC4-4973-44D6-82BD-85431F1E9A09" class="ng-star-inserted">
        <ms-thought-chunk _ngcontent-ng-c1743823686="" _nghost-ng-c166611644="" class="ng-tns-c166611644-11 ng-star-inserted">
            <mat-accordion _ngcontent-ng-c166611644="" displaymode="flat" class="mat-accordion compact-accordion ng-tns-c166611644-11">
                <mat-expansion-panel _ngcontent-ng-c166611644="" class="mat-expansion-panel thought-panel">
                    <img _ngcontent-ng-c166611644="" class="thinking-progress-icon ng-tns-c166611644-11">
                </mat-expansion-panel>
            </mat-accordion>
        </ms-thought-chunk>
        <span class="model-run-time-pill"> 17,4s </span>
    </ms-chat-turn>
    '''
    config_gemini = generator.analyze_html_and_generate_selectors(gemini_thinking_html)
    print(f"Platform: {config_gemini['platform']}")
    print(f"Has thinking: {config_gemini['has_thinking_phase']}")
    if config_gemini['thinking']:
        print(f"Thinking selector: {config_gemini['thinking']['selector']}")
        print(f"Completion indicator: {config_gemini['thinking']['completion_indicator']}")
    print(f"Detection method: {config_gemini['detection']['method']}")
    print(f"Primary selector: {config_gemini['detection']['primary_selector']}")


if __name__ == "__main__":
    test_thinking_support()